{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gSu4VMRHvPP"
      },
      "source": [
        "# EDA and data visualization\n",
        "\n",
        "## EXERCISE 2\n",
        "\n",
        "You have recently started your job in a famous telecom company. As you may very well know, telecoms fiercely fight for customer retention, with entire service branches devoted to this task. This is due to the fact that retention is more cost efficient than capturing new clients. One of your colleagues from the master got hired in the Marketing Department, and he needs to understand the company’s clients, so he’s asked you to help him out with a descriptive report and segmentation of the customer base. **He’s specially interested in the lifetime value of loyal customers.**\n",
        "\n",
        "The purpose of this exercise is to prepare a descriptive report and segment the customers in the most adequate way. Use the data on `customers.csv`. Clean, organise and present an **exploratory analysis** of the data. What can you tell about the customers ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdneYaqeHvPT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set some Pandas options\n",
        "sns.set(style=\"darkgrid\")\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEJXzfSwHvPf"
      },
      "source": [
        "## 1. Preprocessing and Cleaning\n",
        "    \n",
        "As a first part we will go through the data, this way we will clean the csv:\n",
        "- setup corrected types\n",
        "- set index\n",
        "- clean null values\n",
        "- keep relevant data columns and raws\n",
        "\n",
        "**TO DO:**\n",
        "Load the \"customers.csv\" file in a pandas dataframe and display the head."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cV2WSETlHvPh"
      },
      "outputs": [],
      "source": [
        "#If you use google collab:\n",
        "#url =\"https://media.githubusercontent.com/media/michalis0/Business-Intelligence-and-Analytics/master/data/customers.csv\"\n",
        "#customers = pd.read_csv(url)\n",
        "\n",
        "#filename = \"../../data/customers.csv\"\n",
        "#customers = pd.read_csv(filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SI3Vxx9IZl3e"
      },
      "source": [
        "**TO DO:** Display the index, columns, dtypes and shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Yp-tUfAHvPp",
        "scrolled": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Fmgc9HCHvP0"
      },
      "source": [
        "* Modify data types, transform boolean values to correct one. Specially transform True/False values to catagories 0 and 1. The first step is to get the different values uniques present in each column. Then discretize to numerical values.\n",
        "\n",
        "Firstly let's take a look to the tenure column. Since the tenure correspond to the Number of months the customer has stayed with the company, it is important to check null or 0 values.\n",
        "\n",
        "**TO DO:** Firstly you will focus on the tenure columns acces with: `customers.tenure` or `customers['tenure']`. Check  and count the number of raws when `tenure == 0`. To test the values of a raw for a specific column value, you may used the ``.loc[]`` s.t: ``customers.loc[customers.tenure == 0]``\n",
        "\n",
        "Finally to count the number of 0 values you apply the ``..count()``. This function will sum up the total of 0 values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwWpcGqfHvP3",
        "scrolled": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4FALZQYHvP8"
      },
      "source": [
        "**Note:** These 11 raws with be deleted later, this clearly correspond to outliers which maybe start a contract and cancelled befopre its application, or the data is simply missing. Note also that these raws with be dropped by the next steps (check empty string, nan values etc...)\n",
        "\n",
        "The following piece of code allow you to identify uniques values for each columns. The 2 arguments represent the range of the number of uniques values you are looking for. This function return the interested columns that contains this number of unique values (it will be useful later to clean the columns)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3R-aZSXGHvP_"
      },
      "outputs": [],
      "source": [
        "def identify_uniques(min_, max_):\n",
        "    columns = list(customers.columns)\n",
        "    print(columns, '\\n')\n",
        "    interested_columns = []\n",
        "    for col in columns:\n",
        "        #Retreive The uniques values of a column\n",
        "        uniques = customers[col].unique().tolist()\n",
        "        # Check if it belong to this range\n",
        "        if len(uniques) >= min_ and len(uniques) < max_ :\n",
        "            print(col, \" uniques values: \", uniques)\n",
        "            interested_columns.append(col)\n",
        "    return interested_columns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4swW59Mb3ugD"
      },
      "source": [
        "Let's take a look for binary and mullticlass columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1x1-eVZHvQC",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "print(\"Binary classes: \")\n",
        "interested_columns = identify_uniques(0, 4)\n",
        "\n",
        "print(\"Multi classes: \")\n",
        "identify_uniques(3, 15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aEtHhqtHvQI"
      },
      "source": [
        "**Note:** We notice that there is several columns that contains only two categories. Some of them contains also the \"No internet service\" and \"No phone service\" fields which can be convert to the \"No\" categorie directly. This will automatically convert the columns to the good pandas type. There is also some special columns with several but \"countable\" classes: *InternetService*, *Contract* and *PayemmentMethod*\n",
        "\n",
        "**TO DO:** Replace the fields with corresponding values, this is an example:  \n",
        "`customers.gender.replace(to_replace=['Female', 'Male'], value=[0, 1], inplace=True)`.\n",
        "Make sure the fields have numerical types.\n",
        "  1. For binary class (columns with 2 different values), replace ['No', 'Yes', 'No internet service', 'No phone service'] by =[0, 1, 0, 0]:  \n",
        " `.replace(to_replace=['No', 'Yes', 'No internet service', 'No phone service'], value=[0, 1, 0, 0]`\n",
        " use the ```interested_columns``` list.\n",
        "  2. For multi class columns\n",
        "    - replace the `gender` column s.t: `['Female', 'Male']` becomes `[0, 1]`\n",
        "    - replace the `InternetService` column s.t: `['DSL', 'Fiber optic']` becomes `[2, 1]`\n",
        "    - replace the `Contract` column s.t: `['Month-to-month', 'One year', 'Two year']` becomes `[0, 1, 2]`\n",
        "    - replace the `PaymentMethod` column s.t: `['Electronic check', 'Mailed check', 'Bank transfer (automatic)', 'Credit card (automatic)']` becomes `[0, 1, 2, 3]`\n",
        "  3. Transform the `TotalCharges` to numerical type with `pd.to_numeric()`, set the argument `errors='coerce` . This set to `Nan` for values that could not be convert to numerical value.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fX76fX8QHvQK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7Z4VaXBHvQQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HE5ZB_O46-rr"
      },
      "source": [
        "**TO DO:** Execute the following code to display the different changes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZT31wktDHvQT"
      },
      "outputs": [],
      "source": [
        "print(\"All multi classes: \")\n",
        "identify_uniques(0, 15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6s2ybl1G743r"
      },
      "source": [
        "**To DO:**Let's check the modified dataframe. Display the head, the types and the new shape. Run the following code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzQ-YuHsHvQY",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "display(customers.head())\n",
        "display(customers.dtypes)\n",
        "display(customers.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqA48ZzlHvQe"
      },
      "source": [
        "**TO DO:**Set index to the id by using `.set_index()`([doc](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.set_index.html)):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbeufX02HvQg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnxI7Yp1HvQl"
      },
      "source": [
        "* Check other Nan values represention (space, tab, foo...), and convert them to Nan values:\n",
        "\n",
        "**TO DO:** Run the following code. For each special empty, null characters, it returns the elements which satisfy the condition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64MxUfwHHvQm",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "sp_chars = ['foo', ' ', '\\r\\n\\t', '', None]\n",
        "for c in sp_chars:\n",
        "    print(\"Test for \", c, \": \", np.where(customers.applymap(lambda x: x == c)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fs7L1qIFHvQp"
      },
      "source": [
        "**Note:** This values was correctly manage during the conversion process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "257T07k6HvQr"
      },
      "source": [
        "**TO DO:**\n",
        "  1. Check if there are some null values. Use `.isnull().sum()`\n",
        "  2. Remove these unwanted raws by using `.dropna(inplace=True)` on the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "guPZ1JgDHvQs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3aYYqnaHvQw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmi-zs02HvQz",
        "scrolled": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3JN6GNiHvQ2"
      },
      "source": [
        "**Note:** 11 nan raws with nan values have been removed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJl3hmdnHvQ3"
      },
      "source": [
        "### 2. Data visualization & Statistics\n",
        "    \n",
        "    \n",
        "* Comparaison of the number of churned customers\n",
        "\n",
        "**TO DO:** Now we will compare the number of churned customers. To do so, we will display a bar plot on `pd.value_counts(customers.churn)` (this function count for each unique value the total count). Then apply the `.plot()``function. Choose and modify correctly the parameters of your plot (set the title and the different axe labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ikRNpnPHvQ4",
        "scrolled": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNWLeTrFHvQ8"
      },
      "source": [
        "* Charges distribution & statistics\n",
        "\n",
        "**TO DO:** We are now interesting of the continuous values columns s.t the tenure and the charges (Total and Monthly). Apply the `.describe()` function for these three fields. Plot the charts for TotalCharges, MonthlyCharges and tenure fields. Apply `.sort_salues(ascending = True)` before plotting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxynlgVZHvQ9",
        "scrolled": false
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVbuFlI2HvRI"
      },
      "source": [
        "### 3. Statistical analysis\n",
        "\n",
        "To extract the differents features of our models, we have to analyse some statistical indicators such that: the correlation between veriable. Specially for the *Churn* columns since in the fututre it will be the target variable.\n",
        "\n",
        "* Correlation between features columns\n",
        "\n",
        "The Pearson correlation coefficient is the most widely used. It measures the strength of the linear relationship between normally distributed variables. When the variables are not normally distributed or the relationship between the variables is not linear, it may be more appropriate to use the Spearman rank correlation method.  \n",
        "\n",
        "We will see that, the feature extraction methods depend if the inputs columns are linearly dependent or not.\n",
        "\n",
        "**To do:**\n",
        "  1. Compute the different correlations ('pearson' and 'spearman', plot correlation regarding the churn column s.t: `.corr(method='pearson')[['Churn]]`. We apply the correlation function other customers but at the end we keep only the Churn column as a dataframe. Keep in mind this important notation and selection.\n",
        "  2. Plot the correlation values for Churn column in a bar plot. We can reuse the previous code but we ask you to sort by values the correlation to finally get a readable bar plot. You code will start like this:  \n",
        "  `customers.corr(method='pearson')['Churn'][:-1].sort_values(ascending = True).` Note that the [:-1] avoid to take into account the self correlation of the Churn column.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTQZ4ZWRHvRJ",
        "scrolled": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1chT3_VHvRN",
        "scrolled": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OR2ap-bKHvRR"
      },
      "source": [
        "**Note:** We are interested about the strongly correlated and uncorrelated columns. The main features that interfer the churning decision are: *Contract*, *tenure*, *PaymentMethod*, *TotalCharges*, *SeniorCitizen*, *MonthlyCharges* and *PaperlessBilling*. Note that the two most correlated features are inversed depending on the method.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZeonxBsHvRT"
      },
      "source": [
        "**Note:**\n",
        "These results seem very consistent with some hypothesis:  \n",
        "- some types of services the customers signed for do not influence its decision to quit the contract\n",
        "- the gender also is not relevant  \n",
        "- the senior categorie is strongly correlated (i.e: we all dies  :sweat:)  \n",
        "- contract, (payment method (linked with contract), charges and tenure are obviously important for a lots of people (there are strongly correlated between them)  \n",
        "- the paperless billing columns is correlated to the MonthlyCharges\n",
        "\n",
        "**TO DO:** Run the following code. It plots the correlation matrix using `sns.heatmap()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCIaPZpwHvRU"
      },
      "outputs": [],
      "source": [
        "corr = customers.corr()\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.title(\"Correlation matrix\")\n",
        "ax = sns.heatmap(\n",
        "    corr,\n",
        "    vmin=-1, vmax=1, center=0,\n",
        "    cmap=sns.cubehelix_palette(200),\n",
        "    square=True\n",
        ")\n",
        "ax.set_xticklabels(\n",
        "    ax.get_xticklabels(),\n",
        "    rotation=45,\n",
        "    horizontalalignment='right'\n",
        ");\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "b0cc462c96df3621bcc58e01fadcdf9264a069c5c4bbf07201077bb349d3c6bf"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}