{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué es una librería en Python? 📚\n",
    "\n",
    "Una **librería en Python** es una colección de módulos y paquetes que contienen código reutilizable para realizar tareas específicas. Estas librerías permiten a los desarrolladores no tener que escribir código desde cero y facilitar la implementación de diversas funcionalidades en sus proyectos. Las librerías abarcan desde operaciones matemáticas, manipulación de datos, hasta la creación de interfaces gráficas y desarrollo web.\n",
    "\n",
    "## Origen de Pandas 🐼\n",
    "\n",
    "**Pandas** es una de las librerías más populares en el ecosistema de Python para la manipulación y análisis de datos. Fue desarrollada por Wes McKinney en 2008 mientras trabajaba en AQR Capital Management, una firma de gestión de activos. McKinney creó Pandas para tener una herramienta más eficiente y flexible que pudiera manejar grandes cantidades de datos de forma sencilla.\n",
    "\n",
    "## Características de Pandas ✨\n",
    "\n",
    "- **DataFrame y Series**: Pandas introduce dos estructuras de datos fundamentales: `DataFrame` y `Series`. Un `DataFrame` es una tabla bidimensional, mientras que una `Series` es un arreglo unidimensional.\n",
    "- **Manipulación de Datos**: Facilita la limpieza, filtrado, y transformación de datos.\n",
    "- **Operaciones de E/S**: Permite la lectura y escritura de datos en varios formatos como CSV, Excel, SQL, JSON, entre otros.\n",
    "- **Integración con otras librerías**: Pandas se integra bien con otras librerías de Python como NumPy, Matplotlib y Scikit-learn.\n",
    "- **Rendimiento**: Optimizada para operaciones de alto rendimiento y uso eficiente de memoria.\n",
    "\n",
    "## Beneficios de usar Pandas 🌟\n",
    "\n",
    "- **Facilidad de Uso**: Proporciona una interfaz intuitiva y sencilla para la manipulación de datos.\n",
    "- **Eficiencia**: Es capaz de manejar grandes volúmenes de datos de manera eficiente.\n",
    "- **Flexibilidad**: Ofrece una amplia gama de herramientas para limpiar, filtrar y transformar datos.\n",
    "- **Compatibilidad**: Se puede integrar con otras herramientas y bibliotecas de análisis de datos y aprendizaje automático.\n",
    "- **Documentación y Comunidad**: Cuenta con una extensa documentación y una comunidad activa que facilita la resolución de problemas y el aprendizaje.\n",
    "\n",
    "## Uso de Pandas en la Actualidad 📊\n",
    "\n",
    "Pandas es ampliamente utilizado en la industria y la academia debido a su capacidad para simplificar el análisis de datos. Es una herramienta esencial para científicos de datos, analistas y desarrolladores que trabajan con grandes conjuntos de datos. Su popularidad se debe a su eficiencia, flexibilidad y facilidad de uso, lo que la convierte en una herramienta indispensable para cualquier proyecto de ciencia de datos.\n",
    "\n",
    "## Ejemplo de Uso de Pandas 💻\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Crear un DataFrame\n",
    "data = {'Nombre': ['Ana', 'Luis', 'Pedro'],\n",
    "        'Edad': [23, 35, 29],\n",
    "        'Ciudad': ['Madrid', 'Barcelona', 'Valencia']}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Mostrar el DataFrame\n",
    "print(df)\n",
    "\n",
    "# Filtrar datos\n",
    "df_mayores_30 = df[df['Edad'] > 30]\n",
    "print(df_mayores_30)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1.1 Lectura de archivos CSV\n",
    "df_water_quality = pd.read_csv('https://raw.githubusercontent.com/gonzalezulises/101_Data_Analytics_Rizoma/master/data/water_potability.csv')\n",
    "print(df_water_quality.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1.2 Lectura de Archivos Excel\n",
    "\n",
    "# Leer un archivo Excel con datos meteorológicos\n",
    "df_weather = pd.read_excel('/Users/gonzalezulises/Documents/GitHub/101_Data_Analytics_Rizoma/data/Pronostico_del_tiempo.xlsx', sheet_name='Hoja 1 - data (1)')\n",
    "print(df_weather.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1.3 Consumo de API\n",
    "\n",
    "import requests\n",
    "\n",
    "# Obtener datos de calidad del aire de una API\n",
    "api_url = \"https://api.openaq.org/v1/latest?country=ES&parameter=pm25\"\n",
    "response = requests.get(api_url)\n",
    "air_quality_data = response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convertir los datos de la API a un DataFrame\n",
    "df_air_quality = pd.DataFrame(air_quality_data['results'])\n",
    "print(df_air_quality.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2: Análisis de Datos con Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Exploración Inicial de Datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Usando el DataFrame de calidad del agua\n",
    "print(df_water_quality.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_water_quality.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar valores nulos\n",
    "print(df_water_quality.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.2 Selección y Filtrado de Datos\n",
    "\n",
    "# Seleccionar columnas específicas\n",
    "ph_and_temp = df_water_quality[['pH', 'Temperature']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar datos\n",
    "high_ph = df_water_quality[df_water_quality['pH'] > 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.3 Agrupación y Agregación\n",
    "\n",
    "# Agrupar por ubicación y calcular promedios\n",
    "avg_by_location = df_water_quality.groupby('Location').mean()\n",
    "print(avg_by_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2.4 Operaciones con Series y DataFrames\n",
    "\n",
    "# Añadir una nueva columna\n",
    "df_water_quality['pH_category'] = pd.cut(df_water_quality['pH'], \n",
    "                                         bins=[0, 6.5, 7.5, 14],\n",
    "                                         labels=['Acidic', 'Neutral', 'Alkaline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_water_quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operaciones entre columnas\n",
    "df_weather['diferencia_temperatura'] = df_weather['Temperatura Máxima'] - df_weather['Temperatura Mínima']\n",
    "df_weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.5 Manejo de Datos Faltantes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_water_quality.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar si hay valores NaN en el DataFrame\n",
    "tiene_NaN = df_water_quality.isnull().values.any()\n",
    "print(f\"¿El DataFrame tiene valores NaN?: {tiene_NaN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar el número de valores NaN en cada columna\n",
    "NaN_por_columna = df_water_quality.isnull().sum()\n",
    "print(\"Número de valores NaN en cada columna:\")\n",
    "print(NaN_por_columna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el número total de filas\n",
    "total_columnas = df_water_quality.shape[0]\n",
    "total_columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el porcentaje de NaN en cada columna\n",
    "porcentaje_NaN= ((NaN_por_columna / total_columnas) * 100).round(2)\n",
    "print(\"Porcentaje de valores NaN en cada columna:\")\n",
    "print(porcentaje_NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Cómo se manejan los datos faltantes en un análisis estadístico?\n",
    "\n",
    "El manejo de datos faltantes es crucial en el análisis estadístico. Cuando los valores no están disponibles (por ejemplo, registros incompletos o errores), existen estrategias para abordarlos:\n",
    "\n",
    "- Eliminar filas con datos faltantes:\n",
    "Si la cantidad de datos faltantes es pequeña, puedes eliminar las filas correspondientes. Sin embargo, esto puede reducir el tamaño del conjunto de datos.\n",
    "- Imputación (relleno) de valores:\n",
    "  - Media o mediana: Reemplaza los valores faltantes por la media o mediana de la variable.\n",
    "  - Moda: Usa la moda (valor más común) para imputar datos categóricos.\n",
    "  - Imputación múltiple: Crea múltiples conjuntos de datos imputados y combínalos para reducir el sesgo.\n",
    "- Técnicas avanzadas:\n",
    "  - Modelos de aprendizaje automático: Utiliza algoritmos para predecir valores faltantes basándose en otras variables.\n",
    "  - Imputación basada en reglas: Define reglas específicas para imputar valores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Hay algún criterio estadístico?\n",
    "\n",
    "No existe un umbral específico universalmente aceptado para el porcentaje máximo de datos faltantes en una columna. La decisión depende del contexto y del rol de la variable en el análisis. Algunos puntos a considerar:\n",
    "\n",
    "+ Importancia de la variable:\n",
    "  - Si la columna representa una variable crítica o una respuesta en un modelo, incluso un pequeño porcentaje de datos faltantes puede ser problemático.\n",
    "  - Si es una variable menos relevante, puedes ser más tolerante con los valores faltantes.\n",
    "+ Tipo de análisis:\n",
    "  - En análisis exploratorio, se permite más flexibilidad. Sin embargo, en modelos predictivos o inferenciales, los datos faltantes pueden afectar los resultados.\n",
    "  - En estudios observacionales, se puede aceptar un mayor porcentaje de datos faltantes que en ensayos controlados.\n",
    "+ Tamaño de la muestra:\n",
    "  - Si el conjunto de datos es grande, un porcentaje bajo de datos faltantes puede ser manejable.\n",
    "  - En muestras pequeñas, incluso un pequeño porcentaje puede afectar la validez.\n",
    "+ Técnicas de imputación:\n",
    "  - Si puedes imputar valores faltantes de manera confiable (por ejemplo, mediante imputación múltiple), puedes ser más flexible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminación de Filas o Columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicar el dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_water_quality_copy = df_water_quality.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_water_quality_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminar una Columna\n",
    "\n",
    "Para eliminar una columna del DataFrame, utilizaremos el método `drop()`. Asegúrate de especificar el argumento `axis=1` para indicar que estás eliminando una columna y, opcionalmente, puedes usar `inplace=True` si deseas modificar el DataFrame directamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_water_quality_copy.drop('Sulfate', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Imputación Simple con la media\n",
    "Reemplazaremos los valores NaN con la media de la columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_water_quality_copy['ph'].fillna(df_water_quality_copy['ph'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_water_quality_copy.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputación Simple con la mediana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_water_quality_copy['Trihalomethanes'].fillna(df_water_quality_copy['Trihalomethanes'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_water_quality_copy.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputación Simple con la moda\n",
    "\n",
    "Reemplazar valores NaN con la moda de la columna (más común para datos categóricos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_water_quality_copy['ph_category'].fillna(df_water_quality_copy['ph_category'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_water_quality_copy.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios Prácticos\n",
    "\n",
    "- Carga un conjunto de datos de precipitaciones mensuales desde el mi repositorio github (https://raw.githubusercontent.com/gonzalezulises/detodounpoco/main/PREC_2021_Provincias.csv) y resuelve los siguientes ejercicios:\n",
    "\n",
    "1. Calcula la precipitación anual por región y muestra las 5 regiones más lluviosas. Usa `groupby()` para agrupar por región, `sum()` para sumar precipitaciones, `sort_values()` para ordenar y `head()` para mostrar las top 5.\n",
    "\n",
    "2. Encuentra los 3 meses más lluviosos y los 3 más secos en promedio para toda España. Utiliza `melt()` para reestructurar el DataFrame, `groupby()` para agrupar por mes, `mean()` para calcular promedios, `sort_values()` para ordenar y `head()` para seleccionar los extremos.\n",
    "\n",
    "3. Agrupa las regiones por niveles de precipitación anual (bajo: <500mm, medio: 500-1000mm, alto: >1000mm). Emplea `cut()` para categorizar las precipitaciones y `value_counts()` para contar las regiones en cada categoría.\n",
    "\n",
    "4. Crea un DataFrame con la variación mensual de precipitaciones para las 5 regiones más lluviosas. Usa `set_index()` para establecer las regiones como índice, `nlargest()` para seleccionar las top 5 regiones basadas en precipitación anual, y `T` para transponer el resultado si es necesario.\n",
    "\n",
    "5. Identifica regiones con condiciones extremas: a) al menos un mes >200mm, b) al menos tres meses consecutivos <10mm. Utiliza `melt()` para reestructurar, `groupby()` con `any()` para identificar meses >200mm, y `rolling()` con `all()` para periodos consecutivos <10mm.\n",
    "\n",
    "6. Calcula la correlación entre la precipitación de verano (junio, julio, agosto) y la anual. Selecciona las columnas relevantes con `[]` y usa `corr()` para calcular la correlación.\n",
    "\n",
    "7. Prepara un DataFrame para un mapa de calor de precipitaciones mensuales por región. Emplea `set_index()` para establecer las regiones como índice y selecciona solo las columnas de los meses con `[]`.\n",
    "\n",
    "8. Analiza la estacionalidad calculando el porcentaje de precipitación por estación para cada región. Agrupa los meses por estaciones usando `[]`, luego aplica `groupby()` y `sum()` para totales estacionales, y `apply()` con una función lambda para calcular porcentajes.\n",
    "\n",
    "9. Compara precipitaciones entre regiones costeras e interiores. Usa `isin()` para clasificar regiones como costeras o interiores, `groupby()` para agrupar por tipo, y `agg()` para calcular estadísticas descriptivas por grupo.\n",
    "\n",
    "10. Identifica posibles anomalías en los datos de precipitación mensual. Utiliza `melt()` para reestructurar, `groupby()` con `quantile()` para calcular umbrales de anomalías, y `query()` para filtrar valores atípicos basados en estos umbrales.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio de presentación del concepto 'Tidy Data'\n",
    "\n",
    "Analicemos el siguiente archivo del Instituto de Meteorología e Hidrología de Panamá: https://www.imhpa.gob.pa/es/documentos, el archivo: 'Aportes Acumulados de los Embalses Bayano, Fortuna y Changuinola I'\n",
    "\n",
    "Una base de datos tidy es una base de datos en la cuál\n",
    "+ Cada variable que se medida debe estar en una columna.\n",
    "+ Cada observación distinta de esa variable debe estar en una fila diferente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta = '/content/aportes_acumulados_de_los_embalses_bayanofortuna_y_changuinola-861562722.xls'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 1: Leer el Archivo Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embalses = pd.read_excel(ruta, header=None, sheet_name='Datos')\n",
    "df_embalses.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 2: Inspeccionar y Limpiar el DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_embalses.head(20))  # Muestra las primeras 20 filas para inspeccionar el formato"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 3: Separar y Renombrar las Columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para Embalse Bayano\n",
    "df_bayano = df_embalses.iloc[3:34, 0:6]\n",
    "df_bayano.columns = ['Fecha', 'Historico (1976-2023)', 'Húmedo 2010', 'Seco 1976', '2023', '2024']\n",
    "df_bayano['Embalse'] = 'Bayano'\n",
    "df_bayano.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para Embalse Fortuna\n",
    "df_fortuna = df_embalses.iloc[3:34, 6:12]\n",
    "df_fortuna.columns = ['Fecha', 'Historico (1994-2023)', 'Húmedo 1970', 'Seco 1983', '2023', '2024']\n",
    "df_fortuna['Embalse'] = 'Fortuna'\n",
    "df_fortuna.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para Embalse Changuinola I\n",
    "df_changuinola = df_embalses.iloc[3:34, 12:18]  # Ajusta el rango de columnas según sea necesario\n",
    "df_changuinola.columns = ['Fecha', 'Historico (2012-2023)', 'Seco 2013', 'Húmedo 2008','2023','2024']\n",
    "df_changuinola['Embalse'] = 'Changuinola I'\n",
    "df_changuinola.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 4: Transformamos el DataFrame para obtener un formato tidy para los años 2023 y 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bayano_tidy = pd.melt(df_bayano,id_vars=['Fecha'], value_vars=['2023', '2024'],var_name='Categoria',value_name='Valor')\n",
    "df_bayano_tidy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bayano_tidy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos evidenciar que el formato de la columna valor, requiere una transformación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos la columna 'Valor' a float\n",
    "df_bayano_tidy['Valor'] = pd.to_numeric(df_bayano_tidy['Valor'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenamos el DataFrame por Fecha y Categoria\n",
    "df_bayano_tidy = df_bayano_tidy.sort_values(['Fecha', 'Categoria']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos la información sobre el DataFrame para verificar el tipo de datos\n",
    "print(\"Información del DataFrame:\")\n",
    "print(df_bayano_tidy.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos las primeras filas del DataFrame\n",
    "print(\"\\nPrimeras filas del DataFrame:\")\n",
    "print(df_bayano_tidy.head().round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos las estadísticas descriptivas de la columna 'Valor'\n",
    "print(\"\\nEstadísticas descriptivas de la columna 'Valor':\")\n",
    "print(df_bayano_tidy['Valor'].describe().round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos si hay valores nulos después de la conversión\n",
    "print(\"\\nNúmero de valores nulos en la columna 'Valor':\")\n",
    "print(df_bayano_tidy['Valor'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio: Replica el ejercicio para los 2 embalses restantes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
