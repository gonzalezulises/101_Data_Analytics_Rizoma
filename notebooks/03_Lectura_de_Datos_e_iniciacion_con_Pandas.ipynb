{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sesión 2: Lectura de Datos y Análisis con Pandas en Ciencias Ambientales\n",
    "\n",
    "## Parte 1: Lectura de Archivos y Consumo de APIs\n",
    "\n",
    "### 1.1 Lectura de Archivos CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1.2 Lectura de Archivos Excel\n",
    "\n",
    "# Leer un archivo Excel con datos meteorológicos\n",
    "df_weather = pd.read_excel('/Users/gonzalezulises/Documents/GitHub/101_Data_Analytics_Rizoma/data/Pronostico_del_tiempo.xlsx', sheet_name='Hoja 1 - data (1)')\n",
    "print(df_weather.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Leer un archivo Excel con datos meteorológicos\n",
    "df_weather = pd.read_excel('/Users/gonzalezulises/Documents/GitHub/101_Data_Analytics_Rizoma/data/Pronostico_del_tiempo.xlsx', sheet_name='Hoja 1 - data (1)')\n",
    "print(df_weather.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1.3 Consumo de API\n",
    "\n",
    "import requests\n",
    "\n",
    "# Obtener datos de calidad del aire de una API\n",
    "api_url = \"https://api.openaq.org/v1/latest?country=ES&parameter=pm25\"\n",
    "response = requests.get(api_url)\n",
    "air_quality_data = response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convertir los datos de la API a un DataFrame\n",
    "df_air_quality = pd.DataFrame(air_quality_data['results'])\n",
    "print(df_air_quality.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2: Análisis de Datos con Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer un archivo CSV con datos de calidad del agua\n",
    "df_water_quality = pd.read_csv('https://raw.githubusercontent.com/gonzalezulises/101_Data_Analytics_Rizoma/master/data/water_potability.csv')\n",
    "print(df_water_quality.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Exploración Inicial de Datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Usando el DataFrame de calidad del agua\n",
    "print(df_water_quality.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_water_quality.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar valores nulos\n",
    "print(df_water_quality.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.2 Selección y Filtrado de Datos\n",
    "\n",
    "# Seleccionar columnas específicas\n",
    "ph_and_temp = df_water_quality[['pH', 'Temperature']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar datos\n",
    "high_ph = df_water_quality[df_water_quality['pH'] > 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.3 Agrupación y Agregación\n",
    "\n",
    "# Agrupar por ubicación y calcular promedios\n",
    "avg_by_location = df_water_quality.groupby('Location').mean()\n",
    "print(avg_by_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2.4 Operaciones con Series y DataFrames\n",
    "\n",
    "# Añadir una nueva columna\n",
    "df_water_quality['pH_category'] = pd.cut(df_water_quality['pH'], \n",
    "                                         bins=[0, 6.5, 7.5, 14],\n",
    "                                         labels=['Acidic', 'Neutral', 'Alkaline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_water_quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operaciones entre columnas\n",
    "df_weather['diferencia_temperatura'] = df_weather['Temperatura Máxima'] - df_weather['Temperatura Mínima']\n",
    "df_weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.5 Manejo de Datos Faltantes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_water_quality.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar si hay valores NaN en el DataFrame\n",
    "tiene_NaN = df_water_quality.isnull().values.any()\n",
    "print(f\"¿El DataFrame tiene valores NaN?: {tiene_NaN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar el número de valores NaN en cada columna\n",
    "NaN_por_columna = df_water_quality.isnull().sum()\n",
    "print(\"Número de valores NaN en cada columna:\")\n",
    "print(NaN_por_columna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el número total de filas\n",
    "total_columnas = df_water_quality.shape[0]\n",
    "total_columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el porcentaje de NaN en cada columna\n",
    "porcentaje_NaN= ((NaN_por_columna / total_columnas) * 100).round(2)\n",
    "print(\"Porcentaje de valores NaN en cada columna:\")\n",
    "print(porcentaje_NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Cómo se manejan los datos faltantes en un análisis estadístico?\n",
    "\n",
    "El manejo de datos faltantes es crucial en el análisis estadístico. Cuando los valores no están disponibles (por ejemplo, registros incompletos o errores), existen estrategias para abordarlos:\n",
    "\n",
    "- Eliminar filas con datos faltantes:\n",
    "Si la cantidad de datos faltantes es pequeña, puedes eliminar las filas correspondientes. Sin embargo, esto puede reducir el tamaño del conjunto de datos.\n",
    "- Imputación (relleno) de valores:\n",
    "  - Media o mediana: Reemplaza los valores faltantes por la media o mediana de la variable.\n",
    "  - Moda: Usa la moda (valor más común) para imputar datos categóricos.\n",
    "  - Imputación múltiple: Crea múltiples conjuntos de datos imputados y combínalos para reducir el sesgo.\n",
    "- Técnicas avanzadas:\n",
    "  - Modelos de aprendizaje automático: Utiliza algoritmos para predecir valores faltantes basándose en otras variables.\n",
    "  - Imputación basada en reglas: Define reglas específicas para imputar valores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Hay algún criterio estadístico?\n",
    "\n",
    "No existe un umbral específico universalmente aceptado para el porcentaje máximo de datos faltantes en una columna. La decisión depende del contexto y del rol de la variable en el análisis. Algunos puntos a considerar:\n",
    "\n",
    "+ Importancia de la variable:\n",
    "  - Si la columna representa una variable crítica o una respuesta en un modelo, incluso un pequeño porcentaje de datos faltantes puede ser problemático.\n",
    "  - Si es una variable menos relevante, puedes ser más tolerante con los valores faltantes.\n",
    "+ Tipo de análisis:\n",
    "  - En análisis exploratorio, se permite más flexibilidad. Sin embargo, en modelos predictivos o inferenciales, los datos faltantes pueden afectar los resultados.\n",
    "  - En estudios observacionales, se puede aceptar un mayor porcentaje de datos faltantes que en ensayos controlados.\n",
    "+ Tamaño de la muestra:\n",
    "  - Si el conjunto de datos es grande, un porcentaje bajo de datos faltantes puede ser manejable.\n",
    "  - En muestras pequeñas, incluso un pequeño porcentaje puede afectar la validez.\n",
    "+ Técnicas de imputación:\n",
    "  - Si puedes imputar valores faltantes de manera confiable (por ejemplo, mediante imputación múltiple), puedes ser más flexible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminación de Filas o Columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicar el dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_water_quality_copy = df_water_quality.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_water_quality_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminar una Columna\n",
    "\n",
    "Para eliminar una columna del DataFrame, utilizaremos el método `drop()`. Asegúrate de especificar el argumento `axis=1` para indicar que estás eliminando una columna y, opcionalmente, puedes usar `inplace=True` si deseas modificar el DataFrame directamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_water_quality_copy.drop('Sulfate', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Imputación Simple con la media\n",
    "Reemplazaremos los valores NaN con la media de la columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_water_quality_copy['ph'].fillna(df_water_quality_copy['ph'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_water_quality_copy.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputación Simple con la mediana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_water_quality_copy['Trihalomethanes'].fillna(df_water_quality_copy['Trihalomethanes'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_water_quality_copy.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputación Simple con la moda\n",
    "\n",
    "Reemplazar valores NaN con la moda de la columna (más común para datos categóricos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_water_quality_copy['ph_category'].fillna(df_water_quality_copy['ph_category'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_water_quality_copy.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios Prácticos\n",
    "\n",
    "- Carga un conjunto de datos de precipitaciones mensuales desde el mi repositorio github (https://raw.githubusercontent.com/gonzalezulises/detodounpoco/main/PREC_2021_Provincias.csv) y resuelve los siguientes ejercicios:\n",
    "\n",
    "1. Calcula la precipitación anual por región y muestra las 5 regiones más lluviosas. Usa `groupby()` para agrupar por región, `sum()` para sumar precipitaciones, `sort_values()` para ordenar y `head()` para mostrar las top 5.\n",
    "\n",
    "2. Encuentra los 3 meses más lluviosos y los 3 más secos en promedio para toda España. Utiliza `melt()` para reestructurar el DataFrame, `groupby()` para agrupar por mes, `mean()` para calcular promedios, `sort_values()` para ordenar y `head()` para seleccionar los extremos.\n",
    "\n",
    "3. Agrupa las regiones por niveles de precipitación anual (bajo: <500mm, medio: 500-1000mm, alto: >1000mm). Emplea `cut()` para categorizar las precipitaciones y `value_counts()` para contar las regiones en cada categoría.\n",
    "\n",
    "4. Crea un DataFrame con la variación mensual de precipitaciones para las 5 regiones más lluviosas. Usa `set_index()` para establecer las regiones como índice, `nlargest()` para seleccionar las top 5 regiones basadas en precipitación anual, y `T` para transponer el resultado si es necesario.\n",
    "\n",
    "5. Identifica regiones con condiciones extremas: a) al menos un mes >200mm, b) al menos tres meses consecutivos <10mm. Utiliza `melt()` para reestructurar, `groupby()` con `any()` para identificar meses >200mm, y `rolling()` con `all()` para periodos consecutivos <10mm.\n",
    "\n",
    "6. Calcula la correlación entre la precipitación de verano (junio, julio, agosto) y la anual. Selecciona las columnas relevantes con `[]` y usa `corr()` para calcular la correlación.\n",
    "\n",
    "7. Prepara un DataFrame para un mapa de calor de precipitaciones mensuales por región. Emplea `set_index()` para establecer las regiones como índice y selecciona solo las columnas de los meses con `[]`.\n",
    "\n",
    "8. Analiza la estacionalidad calculando el porcentaje de precipitación por estación para cada región. Agrupa los meses por estaciones usando `[]`, luego aplica `groupby()` y `sum()` para totales estacionales, y `apply()` con una función lambda para calcular porcentajes.\n",
    "\n",
    "9. Compara precipitaciones entre regiones costeras e interiores. Usa `isin()` para clasificar regiones como costeras o interiores, `groupby()` para agrupar por tipo, y `agg()` para calcular estadísticas descriptivas por grupo.\n",
    "\n",
    "10. Identifica posibles anomalías en los datos de precipitación mensual. Utiliza `melt()` para reestructurar, `groupby()` con `quantile()` para calcular umbrales de anomalías, y `query()` para filtrar valores atípicos basados en estos umbrales.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soluciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/gonzalezulises/detodounpoco/main/PREC_2021_Provincias.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Precipitación anual por región y top 5 más lluviosas\n",
    "precipitacion_anual = df.groupby('region')['anual'].sum().sort_values(ascending=False)\n",
    "print(\"Top 5 regiones más lluviosas:\")\n",
    "print(precipitacion_anual.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. 3 meses más lluviosos y 3 más secos en promedio\n",
    "# Identificar las columnas mensuales\n",
    "meses = ['Ene', 'Feb', 'Mar', 'Abr', 'May', 'Jun', 'Jul', 'Ago', 'Sep', 'Oct', 'Nov', 'Dic']\n",
    "\n",
    "# Calcular el promedio de precipitación para cada mes\n",
    "precipitacion_mensual = df[meses].mean().sort_values(ascending=False)\n",
    "\n",
    "# Mostrar los 3 meses más lluviosos\n",
    "print(\"3 meses más lluviosos:\")\n",
    "print(precipitacion_mensual.head(3))\n",
    "\n",
    "# Mostrar los 3 meses más secos\n",
    "print(\"\\n3 meses más secos:\")\n",
    "print(precipitacion_mensual.tail(3))\n",
    "\n",
    "# Si quieres ver todos los meses ordenados\n",
    "print(\"\\nTodos los meses ordenados por precipitación:\")\n",
    "print(precipitacion_mensual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. Agrupar regiones por niveles de precipitación anual\n",
    "df['categoria_precipitacion'] = pd.cut(df['anual'], \n",
    "                                       bins=[0, 500, 1000, float('inf')], \n",
    "                                       labels=['Bajo', 'Medio', 'Alto'])\n",
    "conteo_categorias = df['categoria_precipitacion'].value_counts()\n",
    "print(\"\\nConteo de regiones por categoría de precipitación:\")\n",
    "print(conteo_categorias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4. Variación mensual de precipitaciones para las 5 regiones más lluviosas\n",
    "top_5_regiones = df.nlargest(5, 'anual')['region'].tolist()\n",
    "df_top_5 = df[df['region'].isin(top_5_regiones)].set_index('region')\n",
    "df_top_5_mensual = df_top_5.loc[:, 'enero':'diciembre']\n",
    "print(\"\\nVariación mensual de precipitaciones para las 5 regiones más lluviosas:\")\n",
    "print(df_top_5_mensual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5. Identificar regiones con condiciones extremas\n",
    "df_melt = df.melt(id_vars=['Parametro', 'region', 'anual'], \n",
    "                  var_name='mes', value_name='precipitacion')\n",
    "regiones_extremas = df_melt.groupby('region').agg(\n",
    "    max_precipitacion=('precipitacion', 'max'),\n",
    "    meses_secos=('precipitacion', lambda x: (x < 10).rolling(3).sum().max())\n",
    ")\n",
    "regiones_extremas = regiones_extremas[\n",
    "    (regiones_extremas['max_precipitacion'] > 200) | \n",
    "    (regiones_extremas['meses_secos'] >= 3)\n",
    "]\n",
    "print(\"\\nRegiones con condiciones extremas:\")\n",
    "print(regiones_extremas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 6. Correlación entre precipitación de verano y anual\n",
    "df['precipitacion_verano'] = df[['junio', 'julio', 'agosto']].sum(axis=1)\n",
    "correlacion = df['precipitacion_verano'].corr(df['anual'])\n",
    "print(f\"\\nCorrelación entre precipitación de verano y anual: {correlacion:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 7. Preparar DataFrame para mapa de calor\n",
    "df_heatmap = df.set_index('region').loc[:, 'enero':'diciembre']\n",
    "print(\"\\nDataFrame para mapa de calor de precipitaciones mensuales:\")\n",
    "print(df_heatmap.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 8. Analizar estacionalidad\n",
    "df['primavera'] = df[['marzo', 'abril', 'mayo']].sum(axis=1)\n",
    "df['verano'] = df[['junio', 'julio', 'agosto']].sum(axis=1)\n",
    "df['otono'] = df[['septiembre', 'octubre', 'noviembre']].sum(axis=1)\n",
    "df['invierno'] = df[['diciembre', 'enero', 'febrero']].sum(axis=1)\n",
    "\n",
    "df_estaciones = df[['region', 'primavera', 'verano', 'otono', 'invierno', 'anual']]\n",
    "df_estaciones_pct = df_estaciones.set_index('region').apply(lambda x: x / x['anual'] * 100)\n",
    "print(\"\\nPorcentaje de precipitación por estación:\")\n",
    "print(df_estaciones_pct.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 9. Comparar precipitaciones entre regiones costeras e interiores\n",
    "regiones_costeras = ['A CORUNA', 'ASTURIAS', 'CANTABRIA', 'BIZKAIA', 'GIPUZKOA', 'BARCELONA', \n",
    "                     'TARRAGONA', 'CASTELLON', 'VALENCIA', 'ALICANTE', 'MURCIA', 'ALMERIA', \n",
    "                     'GRANADA', 'MALAGA', 'CADIZ', 'HUELVA', 'PONTEVEDRA', 'ILLES BALEARS', \n",
    "                     'LAS PALMAS', 'SANTA CRUZ DE TENERIFE', 'CEUTA', 'MELILLA']\n",
    "\n",
    "df['tipo_region'] = df['region'].apply(lambda x: 'Costera' if x in regiones_costeras else 'Interior')\n",
    "comparacion = df.groupby('tipo_region')['anual'].agg(['mean', 'median', 'std'])\n",
    "print(\"\\nComparación de precipitaciones entre regiones costeras e interiores:\")\n",
    "print(comparacion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 10. Identificar posibles anomalías\n",
    "df_melt = df.melt(id_vars=['Parametro', 'region', 'anual'], \n",
    "                  var_name='mes', value_name='precipitacion')\n",
    "df_melt['z_score'] = df_melt.groupby('mes')['precipitacion'].transform(\n",
    "    lambda x: (x - x.mean()) / x.std()\n",
    ")\n",
    "anomalias = df_melt[df_melt['z_score'].abs() > 3]\n",
    "print(\"\\nPosibles anomalías en los datos de precipitación:\")\n",
    "print(anomalias[['region', 'mes', 'precipitacion', 'z_score']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio de presentación del concepto 'Tidy Data'\n",
    "\n",
    "Analicemos el siguiente archivo del Instituto de Meteorología e Hidrología de Panamá: https://www.imhpa.gob.pa/es/documentos, el archivo: 'Aportes Acumulados de los Embalses Bayano, Fortuna y Changuinola I'\n",
    "\n",
    "Una base de datos tidy es una base de datos en la cuál\n",
    "+ Cada variable que se medida debe estar en una columna.\n",
    "+ Cada observación distinta de esa variable debe estar en una fila diferente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta = '/content/aportes_acumulados_de_los_embalses_bayanofortuna_y_changuinola-861562722.xls'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 1: Leer el Archivo Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embalses = pd.read_excel(ruta, header=None, sheet_name='Datos')\n",
    "df_embalses.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 2: Inspeccionar y Limpiar el DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_embalses.head(20))  # Muestra las primeras 20 filas para inspeccionar el formato"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 3: Separar y Renombrar las Columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para Embalse Bayano\n",
    "df_bayano = df_embalses.iloc[3:34, 0:6]\n",
    "df_bayano.columns = ['Fecha', 'Historico (1976-2023)', 'Húmedo 2010', 'Seco 1976', '2023', '2024']\n",
    "df_bayano['Embalse'] = 'Bayano'\n",
    "df_bayano.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para Embalse Fortuna\n",
    "df_fortuna = df_embalses.iloc[3:34, 6:12]\n",
    "df_fortuna.columns = ['Fecha', 'Historico (1994-2023)', 'Húmedo 1970', 'Seco 1983', '2023', '2024']\n",
    "df_fortuna['Embalse'] = 'Fortuna'\n",
    "df_fortuna.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para Embalse Changuinola I\n",
    "df_changuinola = df_embalses.iloc[3:34, 12:18]  # Ajusta el rango de columnas según sea necesario\n",
    "df_changuinola.columns = ['Fecha', 'Historico (2012-2023)', 'Seco 2013', 'Húmedo 2008','2023','2024']\n",
    "df_changuinola['Embalse'] = 'Changuinola I'\n",
    "df_changuinola.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 4: Transformamos el DataFrame para obtener un formato tidy para los años 2023 y 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bayano_tidy = pd.melt(df_bayano,id_vars=['Fecha'], value_vars=['2023', '2024'],var_name='Categoria',value_name='Valor')\n",
    "df_bayano_tidy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bayano_tidy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos evidenciar que el formato de la columna valor, requiere una transformación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos la columna 'Valor' a float\n",
    "df_bayano_tidy['Valor'] = pd.to_numeric(df_bayano_tidy['Valor'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenamos el DataFrame por Fecha y Categoria\n",
    "df_bayano_tidy = df_bayano_tidy.sort_values(['Fecha', 'Categoria']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos la información sobre el DataFrame para verificar el tipo de datos\n",
    "print(\"Información del DataFrame:\")\n",
    "print(df_bayano_tidy.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos las primeras filas del DataFrame\n",
    "print(\"\\nPrimeras filas del DataFrame:\")\n",
    "print(df_bayano_tidy.head().round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos las estadísticas descriptivas de la columna 'Valor'\n",
    "print(\"\\nEstadísticas descriptivas de la columna 'Valor':\")\n",
    "print(df_bayano_tidy['Valor'].describe().round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos si hay valores nulos después de la conversión\n",
    "print(\"\\nNúmero de valores nulos en la columna 'Valor':\")\n",
    "print(df_bayano_tidy['Valor'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio: Replica el ejercicio para los 2 embalses restantes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
