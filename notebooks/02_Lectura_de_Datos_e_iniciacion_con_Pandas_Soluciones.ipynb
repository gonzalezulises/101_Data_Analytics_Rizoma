{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 쯈u칠 es una librer칤a en Python? 游닄\n",
    "\n",
    "Una **librer칤a en Python** es una colecci칩n de m칩dulos y paquetes que contienen c칩digo reutilizable para realizar tareas espec칤ficas. Estas librer칤as permiten a los desarrolladores no tener que escribir c칩digo desde cero y facilitar la implementaci칩n de diversas funcionalidades en sus proyectos. Las librer칤as abarcan desde operaciones matem치ticas, manipulaci칩n de datos, hasta la creaci칩n de interfaces gr치ficas y desarrollo web.\n",
    "\n",
    "## Origen de Pandas 游냪\n",
    "\n",
    "**Pandas** es una de las librer칤as m치s populares en el ecosistema de Python para la manipulaci칩n y an치lisis de datos. Fue desarrollada por Wes McKinney en 2008 mientras trabajaba en AQR Capital Management, una firma de gesti칩n de activos. McKinney cre칩 Pandas para tener una herramienta m치s eficiente y flexible que pudiera manejar grandes cantidades de datos de forma sencilla.\n",
    "\n",
    "## Caracter칤sticas de Pandas 九\n",
    "\n",
    "- **DataFrame y Series**: Pandas introduce dos estructuras de datos fundamentales: `DataFrame` y `Series`. Un `DataFrame` es una tabla bidimensional, mientras que una `Series` es un arreglo unidimensional.\n",
    "- **Manipulaci칩n de Datos**: Facilita la limpieza, filtrado, y transformaci칩n de datos.\n",
    "- **Operaciones de E/S**: Permite la lectura y escritura de datos en varios formatos como CSV, Excel, SQL, JSON, entre otros.\n",
    "- **Integraci칩n con otras librer칤as**: Pandas se integra bien con otras librer칤as de Python como NumPy, Matplotlib y Scikit-learn.\n",
    "- **Rendimiento**: Optimizada para operaciones de alto rendimiento y uso eficiente de memoria.\n",
    "\n",
    "## Beneficios de usar Pandas 游륲n",
    "\n",
    "- **Facilidad de Uso**: Proporciona una interfaz intuitiva y sencilla para la manipulaci칩n de datos.\n",
    "- **Eficiencia**: Es capaz de manejar grandes vol칰menes de datos de manera eficiente.\n",
    "- **Flexibilidad**: Ofrece una amplia gama de herramientas para limpiar, filtrar y transformar datos.\n",
    "- **Compatibilidad**: Se puede integrar con otras herramientas y bibliotecas de an치lisis de datos y aprendizaje autom치tico.\n",
    "- **Documentaci칩n y Comunidad**: Cuenta con una extensa documentaci칩n y una comunidad activa que facilita la resoluci칩n de problemas y el aprendizaje.\n",
    "\n",
    "## Uso de Pandas en la Actualidad 游늵\n",
    "\n",
    "Pandas es ampliamente utilizado en la industria y la academia debido a su capacidad para simplificar el an치lisis de datos. Es una herramienta esencial para cient칤ficos de datos, analistas y desarrolladores que trabajan con grandes conjuntos de datos. Su popularidad se debe a su eficiencia, flexibilidad y facilidad de uso, lo que la convierte en una herramienta indispensable para cualquier proyecto de ciencia de datos.\n",
    "\n",
    "## Ejemplo de Uso de Pandas 游눹\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Crear un DataFrame\n",
    "data = {'Nombre': ['Ana', 'Luis', 'Pedro'],\n",
    "        'Edad': [23, 35, 29],\n",
    "        'Ciudad': ['Madrid', 'Barcelona', 'Valencia']}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Mostrar el DataFrame\n",
    "print(df)\n",
    "\n",
    "# Filtrar datos\n",
    "df_mayores_30 = df[df['Edad'] > 30]\n",
    "print(df_mayores_30)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1.1 Lectura de archivos CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1.2 Lectura de Archivos Excel\n",
    "\n",
    "# Leer un archivo Excel con datos meteorol칩gicos\n",
    "df_weather = pd.read_excel('/Users/gonzalezulises/Documents/GitHub/101_Data_Analytics_Rizoma/data/Pronostico_del_tiempo.xlsx', sheet_name='Hoja 1 - data (1)')\n",
    "print(df_weather.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1.3 Consumo de API\n",
    "\n",
    "import requests\n",
    "\n",
    "# Obtener datos de calidad del aire de una API\n",
    "api_url = \"https://api.openaq.org/v1/latest?country=ES&parameter=pm25\"\n",
    "response = requests.get(api_url)\n",
    "air_quality_data = response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convertir los datos de la API a un DataFrame\n",
    "df_air_quality = pd.DataFrame(air_quality_data['results'])\n",
    "print(df_air_quality.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2: An치lisis de Datos con Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer un archivo CSV con datos de calidad del agua\n",
    "df_water_quality = pd.read_csv('https://raw.githubusercontent.com/gonzalezulises/101_Data_Analytics_Rizoma/master/data/water_potability.csv')\n",
    "print(df_water_quality.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Exploraci칩n Inicial de Datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Usando el DataFrame de calidad del agua\n",
    "print(df_water_quality.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_water_quality.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar valores nulos\n",
    "print(df_water_quality.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.2 Selecci칩n y Filtrado de Datos\n",
    "\n",
    "# Seleccionar columnas espec칤ficas\n",
    "ph_and_temp = df_water_quality[['pH', 'Temperature']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar datos\n",
    "high_ph = df_water_quality[df_water_quality['pH'] > 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.3 Agrupaci칩n y Agregaci칩n\n",
    "\n",
    "# Agrupar por ubicaci칩n y calcular promedios\n",
    "avg_by_location = df_water_quality.groupby('Location').mean()\n",
    "print(avg_by_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2.4 Operaciones con Series y DataFrames\n",
    "\n",
    "# A침adir una nueva columna\n",
    "df_water_quality['pH_category'] = pd.cut(df_water_quality['pH'], \n",
    "                                         bins=[0, 6.5, 7.5, 14],\n",
    "                                         labels=['Acidic', 'Neutral', 'Alkaline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_water_quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operaciones entre columnas\n",
    "df_weather['diferencia_temperatura'] = df_weather['Temperatura M치xima'] - df_weather['Temperatura M칤nima']\n",
    "df_weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.5 Manejo de Datos Faltantes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_water_quality.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar si hay valores NaN en el DataFrame\n",
    "tiene_NaN = df_water_quality.isnull().values.any()\n",
    "print(f\"쮼l DataFrame tiene valores NaN?: {tiene_NaN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar el n칰mero de valores NaN en cada columna\n",
    "NaN_por_columna = df_water_quality.isnull().sum()\n",
    "print(\"N칰mero de valores NaN en cada columna:\")\n",
    "print(NaN_por_columna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el n칰mero total de filas\n",
    "total_columnas = df_water_quality.shape[0]\n",
    "total_columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el porcentaje de NaN en cada columna\n",
    "porcentaje_NaN= ((NaN_por_columna / total_columnas) * 100).round(2)\n",
    "print(\"Porcentaje de valores NaN en cada columna:\")\n",
    "print(porcentaje_NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 쮺칩mo se manejan los datos faltantes en un an치lisis estad칤stico?\n",
    "\n",
    "El manejo de datos faltantes es crucial en el an치lisis estad칤stico. Cuando los valores no est치n disponibles (por ejemplo, registros incompletos o errores), existen estrategias para abordarlos:\n",
    "\n",
    "- Eliminar filas con datos faltantes:\n",
    "Si la cantidad de datos faltantes es peque침a, puedes eliminar las filas correspondientes. Sin embargo, esto puede reducir el tama침o del conjunto de datos.\n",
    "- Imputaci칩n (relleno) de valores:\n",
    "  - Media o mediana: Reemplaza los valores faltantes por la media o mediana de la variable.\n",
    "  - Moda: Usa la moda (valor m치s com칰n) para imputar datos categ칩ricos.\n",
    "  - Imputaci칩n m칰ltiple: Crea m칰ltiples conjuntos de datos imputados y comb칤nalos para reducir el sesgo.\n",
    "- T칠cnicas avanzadas:\n",
    "  - Modelos de aprendizaje autom치tico: Utiliza algoritmos para predecir valores faltantes bas치ndose en otras variables.\n",
    "  - Imputaci칩n basada en reglas: Define reglas espec칤ficas para imputar valores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 쮿ay alg칰n criterio estad칤stico?\n",
    "\n",
    "No existe un umbral espec칤fico universalmente aceptado para el porcentaje m치ximo de datos faltantes en una columna. La decisi칩n depende del contexto y del rol de la variable en el an치lisis. Algunos puntos a considerar:\n",
    "\n",
    "+ Importancia de la variable:\n",
    "  - Si la columna representa una variable cr칤tica o una respuesta en un modelo, incluso un peque침o porcentaje de datos faltantes puede ser problem치tico.\n",
    "  - Si es una variable menos relevante, puedes ser m치s tolerante con los valores faltantes.\n",
    "+ Tipo de an치lisis:\n",
    "  - En an치lisis exploratorio, se permite m치s flexibilidad. Sin embargo, en modelos predictivos o inferenciales, los datos faltantes pueden afectar los resultados.\n",
    "  - En estudios observacionales, se puede aceptar un mayor porcentaje de datos faltantes que en ensayos controlados.\n",
    "+ Tama침o de la muestra:\n",
    "  - Si el conjunto de datos es grande, un porcentaje bajo de datos faltantes puede ser manejable.\n",
    "  - En muestras peque침as, incluso un peque침o porcentaje puede afectar la validez.\n",
    "+ T칠cnicas de imputaci칩n:\n",
    "  - Si puedes imputar valores faltantes de manera confiable (por ejemplo, mediante imputaci칩n m칰ltiple), puedes ser m치s flexible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminaci칩n de Filas o Columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicar el dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_water_quality_copy = df_water_quality.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_water_quality_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminar una Columna\n",
    "\n",
    "Para eliminar una columna del DataFrame, utilizaremos el m칠todo `drop()`. Aseg칰rate de especificar el argumento `axis=1` para indicar que est치s eliminando una columna y, opcionalmente, puedes usar `inplace=True` si deseas modificar el DataFrame directamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_water_quality_copy.drop('Sulfate', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Imputaci칩n Simple con la media\n",
    "Reemplazaremos los valores NaN con la media de la columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_water_quality_copy['ph'].fillna(df_water_quality_copy['ph'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_water_quality_copy.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputaci칩n Simple con la mediana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_water_quality_copy['Trihalomethanes'].fillna(df_water_quality_copy['Trihalomethanes'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_water_quality_copy.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputaci칩n Simple con la moda\n",
    "\n",
    "Reemplazar valores NaN con la moda de la columna (m치s com칰n para datos categ칩ricos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_water_quality_copy['ph_category'].fillna(df_water_quality_copy['ph_category'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_water_quality_copy.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios Pr치cticos\n",
    "\n",
    "- Carga un conjunto de datos de precipitaciones mensuales desde el mi repositorio github (https://raw.githubusercontent.com/gonzalezulises/detodounpoco/main/PREC_2021_Provincias.csv) y resuelve los siguientes ejercicios:\n",
    "\n",
    "1. Calcula la precipitaci칩n anual por regi칩n y muestra las 5 regiones m치s lluviosas. Usa `groupby()` para agrupar por regi칩n, `sum()` para sumar precipitaciones, `sort_values()` para ordenar y `head()` para mostrar las top 5.\n",
    "\n",
    "2. Encuentra los 3 meses m치s lluviosos y los 3 m치s secos en promedio para toda Espa침a. Utiliza `melt()` para reestructurar el DataFrame, `groupby()` para agrupar por mes, `mean()` para calcular promedios, `sort_values()` para ordenar y `head()` para seleccionar los extremos.\n",
    "\n",
    "3. Agrupa las regiones por niveles de precipitaci칩n anual (bajo: <500mm, medio: 500-1000mm, alto: >1000mm). Emplea `cut()` para categorizar las precipitaciones y `value_counts()` para contar las regiones en cada categor칤a.\n",
    "\n",
    "4. Crea un DataFrame con la variaci칩n mensual de precipitaciones para las 5 regiones m치s lluviosas. Usa `set_index()` para establecer las regiones como 칤ndice, `nlargest()` para seleccionar las top 5 regiones basadas en precipitaci칩n anual, y `T` para transponer el resultado si es necesario.\n",
    "\n",
    "5. Identifica regiones con condiciones extremas: a) al menos un mes >200mm, b) al menos tres meses consecutivos <10mm. Utiliza `melt()` para reestructurar, `groupby()` con `any()` para identificar meses >200mm, y `rolling()` con `all()` para periodos consecutivos <10mm.\n",
    "\n",
    "6. Calcula la correlaci칩n entre la precipitaci칩n de verano (junio, julio, agosto) y la anual. Selecciona las columnas relevantes con `[]` y usa `corr()` para calcular la correlaci칩n.\n",
    "\n",
    "7. Prepara un DataFrame para un mapa de calor de precipitaciones mensuales por regi칩n. Emplea `set_index()` para establecer las regiones como 칤ndice y selecciona solo las columnas de los meses con `[]`.\n",
    "\n",
    "8. Analiza la estacionalidad calculando el porcentaje de precipitaci칩n por estaci칩n para cada regi칩n. Agrupa los meses por estaciones usando `[]`, luego aplica `groupby()` y `sum()` para totales estacionales, y `apply()` con una funci칩n lambda para calcular porcentajes.\n",
    "\n",
    "9. Compara precipitaciones entre regiones costeras e interiores. Usa `isin()` para clasificar regiones como costeras o interiores, `groupby()` para agrupar por tipo, y `agg()` para calcular estad칤sticas descriptivas por grupo.\n",
    "\n",
    "10. Identifica posibles anomal칤as en los datos de precipitaci칩n mensual. Utiliza `melt()` para reestructurar, `groupby()` con `quantile()` para calcular umbrales de anomal칤as, y `query()` para filtrar valores at칤picos basados en estos umbrales.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soluciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/gonzalezulises/detodounpoco/main/PREC_2021_Provincias.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Precipitaci칩n anual por regi칩n y top 5 m치s lluviosas\n",
    "precipitacion_anual = df.groupby('region')['anual'].sum().sort_values(ascending=False)\n",
    "print(\"Top 5 regiones m치s lluviosas:\")\n",
    "print(precipitacion_anual.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. 3 meses m치s lluviosos y 3 m치s secos en promedio\n",
    "# Identificar las columnas mensuales\n",
    "meses = ['Ene', 'Feb', 'Mar', 'Abr', 'May', 'Jun', 'Jul', 'Ago', 'Sep', 'Oct', 'Nov', 'Dic']\n",
    "\n",
    "# Calcular el promedio de precipitaci칩n para cada mes\n",
    "precipitacion_mensual = df[meses].mean().sort_values(ascending=False)\n",
    "\n",
    "# Mostrar los 3 meses m치s lluviosos\n",
    "print(\"3 meses m치s lluviosos:\")\n",
    "print(precipitacion_mensual.head(3))\n",
    "\n",
    "# Mostrar los 3 meses m치s secos\n",
    "print(\"\\n3 meses m치s secos:\")\n",
    "print(precipitacion_mensual.tail(3))\n",
    "\n",
    "# Si quieres ver todos los meses ordenados\n",
    "print(\"\\nTodos los meses ordenados por precipitaci칩n:\")\n",
    "print(precipitacion_mensual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. Agrupar regiones por niveles de precipitaci칩n anual\n",
    "df['categoria_precipitacion'] = pd.cut(df['anual'], \n",
    "                                       bins=[0, 500, 1000, float('inf')], \n",
    "                                       labels=['Bajo', 'Medio', 'Alto'])\n",
    "conteo_categorias = df['categoria_precipitacion'].value_counts()\n",
    "print(\"\\nConteo de regiones por categor칤a de precipitaci칩n:\")\n",
    "print(conteo_categorias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4. Variaci칩n mensual de precipitaciones para las 5 regiones m치s lluviosas\n",
    "top_5_regiones = df.nlargest(5, 'anual')['region'].tolist()\n",
    "df_top_5 = df[df['region'].isin(top_5_regiones)].set_index('region')\n",
    "df_top_5_mensual = df_top_5.loc[:, 'enero':'diciembre']\n",
    "print(\"\\nVariaci칩n mensual de precipitaciones para las 5 regiones m치s lluviosas:\")\n",
    "print(df_top_5_mensual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5. Identificar regiones con condiciones extremas\n",
    "df_melt = df.melt(id_vars=['Parametro', 'region', 'anual'], \n",
    "                  var_name='mes', value_name='precipitacion')\n",
    "regiones_extremas = df_melt.groupby('region').agg(\n",
    "    max_precipitacion=('precipitacion', 'max'),\n",
    "    meses_secos=('precipitacion', lambda x: (x < 10).rolling(3).sum().max())\n",
    ")\n",
    "regiones_extremas = regiones_extremas[\n",
    "    (regiones_extremas['max_precipitacion'] > 200) | \n",
    "    (regiones_extremas['meses_secos'] >= 3)\n",
    "]\n",
    "print(\"\\nRegiones con condiciones extremas:\")\n",
    "print(regiones_extremas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 6. Correlaci칩n entre precipitaci칩n de verano y anual\n",
    "df['precipitacion_verano'] = df[['junio', 'julio', 'agosto']].sum(axis=1)\n",
    "correlacion = df['precipitacion_verano'].corr(df['anual'])\n",
    "print(f\"\\nCorrelaci칩n entre precipitaci칩n de verano y anual: {correlacion:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 7. Preparar DataFrame para mapa de calor\n",
    "df_heatmap = df.set_index('region').loc[:, 'enero':'diciembre']\n",
    "print(\"\\nDataFrame para mapa de calor de precipitaciones mensuales:\")\n",
    "print(df_heatmap.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 8. Analizar estacionalidad\n",
    "df['primavera'] = df[['marzo', 'abril', 'mayo']].sum(axis=1)\n",
    "df['verano'] = df[['junio', 'julio', 'agosto']].sum(axis=1)\n",
    "df['otono'] = df[['septiembre', 'octubre', 'noviembre']].sum(axis=1)\n",
    "df['invierno'] = df[['diciembre', 'enero', 'febrero']].sum(axis=1)\n",
    "\n",
    "df_estaciones = df[['region', 'primavera', 'verano', 'otono', 'invierno', 'anual']]\n",
    "df_estaciones_pct = df_estaciones.set_index('region').apply(lambda x: x / x['anual'] * 100)\n",
    "print(\"\\nPorcentaje de precipitaci칩n por estaci칩n:\")\n",
    "print(df_estaciones_pct.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 9. Comparar precipitaciones entre regiones costeras e interiores\n",
    "regiones_costeras = ['A CORUNA', 'ASTURIAS', 'CANTABRIA', 'BIZKAIA', 'GIPUZKOA', 'BARCELONA', \n",
    "                     'TARRAGONA', 'CASTELLON', 'VALENCIA', 'ALICANTE', 'MURCIA', 'ALMERIA', \n",
    "                     'GRANADA', 'MALAGA', 'CADIZ', 'HUELVA', 'PONTEVEDRA', 'ILLES BALEARS', \n",
    "                     'LAS PALMAS', 'SANTA CRUZ DE TENERIFE', 'CEUTA', 'MELILLA']\n",
    "\n",
    "df['tipo_region'] = df['region'].apply(lambda x: 'Costera' if x in regiones_costeras else 'Interior')\n",
    "comparacion = df.groupby('tipo_region')['anual'].agg(['mean', 'median', 'std'])\n",
    "print(\"\\nComparaci칩n de precipitaciones entre regiones costeras e interiores:\")\n",
    "print(comparacion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 10. Identificar posibles anomal칤as\n",
    "df_melt = df.melt(id_vars=['Parametro', 'region', 'anual'], \n",
    "                  var_name='mes', value_name='precipitacion')\n",
    "df_melt['z_score'] = df_melt.groupby('mes')['precipitacion'].transform(\n",
    "    lambda x: (x - x.mean()) / x.std()\n",
    ")\n",
    "anomalias = df_melt[df_melt['z_score'].abs() > 3]\n",
    "print(\"\\nPosibles anomal칤as en los datos de precipitaci칩n:\")\n",
    "print(anomalias[['region', 'mes', 'precipitacion', 'z_score']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio de presentaci칩n del concepto 'Tidy Data'\n",
    "\n",
    "Analicemos el siguiente archivo del Instituto de Meteorolog칤a e Hidrolog칤a de Panam치: https://www.imhpa.gob.pa/es/documentos, el archivo: 'Aportes Acumulados de los Embalses Bayano, Fortuna y Changuinola I'\n",
    "\n",
    "Una base de datos tidy es una base de datos en la cu치l\n",
    "+ Cada variable que se medida debe estar en una columna.\n",
    "+ Cada observaci칩n distinta de esa variable debe estar en una fila diferente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta = '/content/aportes_acumulados_de_los_embalses_bayanofortuna_y_changuinola-861562722.xls'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 1: Leer el Archivo Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embalses = pd.read_excel(ruta, header=None, sheet_name='Datos')\n",
    "df_embalses.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 2: Inspeccionar y Limpiar el DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_embalses.head(20))  # Muestra las primeras 20 filas para inspeccionar el formato"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 3: Separar y Renombrar las Columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para Embalse Bayano\n",
    "df_bayano = df_embalses.iloc[3:34, 0:6]\n",
    "df_bayano.columns = ['Fecha', 'Historico (1976-2023)', 'H칰medo 2010', 'Seco 1976', '2023', '2024']\n",
    "df_bayano['Embalse'] = 'Bayano'\n",
    "df_bayano.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para Embalse Fortuna\n",
    "df_fortuna = df_embalses.iloc[3:34, 6:12]\n",
    "df_fortuna.columns = ['Fecha', 'Historico (1994-2023)', 'H칰medo 1970', 'Seco 1983', '2023', '2024']\n",
    "df_fortuna['Embalse'] = 'Fortuna'\n",
    "df_fortuna.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para Embalse Changuinola I\n",
    "df_changuinola = df_embalses.iloc[3:34, 12:18]  # Ajusta el rango de columnas seg칰n sea necesario\n",
    "df_changuinola.columns = ['Fecha', 'Historico (2012-2023)', 'Seco 2013', 'H칰medo 2008','2023','2024']\n",
    "df_changuinola['Embalse'] = 'Changuinola I'\n",
    "df_changuinola.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 4: Transformamos el DataFrame para obtener un formato tidy para los a침os 2023 y 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bayano_tidy = pd.melt(df_bayano,id_vars=['Fecha'], value_vars=['2023', '2024'],var_name='Categoria',value_name='Valor')\n",
    "df_bayano_tidy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bayano_tidy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos evidenciar que el formato de la columna valor, requiere una transformaci칩n de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos la columna 'Valor' a float\n",
    "df_bayano_tidy['Valor'] = pd.to_numeric(df_bayano_tidy['Valor'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenamos el DataFrame por Fecha y Categoria\n",
    "df_bayano_tidy = df_bayano_tidy.sort_values(['Fecha', 'Categoria']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos la informaci칩n sobre el DataFrame para verificar el tipo de datos\n",
    "print(\"Informaci칩n del DataFrame:\")\n",
    "print(df_bayano_tidy.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos las primeras filas del DataFrame\n",
    "print(\"\\nPrimeras filas del DataFrame:\")\n",
    "print(df_bayano_tidy.head().round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos las estad칤sticas descriptivas de la columna 'Valor'\n",
    "print(\"\\nEstad칤sticas descriptivas de la columna 'Valor':\")\n",
    "print(df_bayano_tidy['Valor'].describe().round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos si hay valores nulos despu칠s de la conversi칩n\n",
    "print(\"\\nN칰mero de valores nulos en la columna 'Valor':\")\n",
    "print(df_bayano_tidy['Valor'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio: Replica el ejercicio para los 2 embalses restantes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
